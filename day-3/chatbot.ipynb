{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain langgraph langchain-community chromadb tiktoken gradio langchain_openai langchain-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking state <langgraph.checkpoint.memory.InMemorySaver object at 0x147a546a0>\n",
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint state before None\n",
      "Checkpoint state after {'v': 4, 'ts': '2026-01-16T05:25:45.488119+00:00', 'id': '1f0f29bc-efac-6e46-8001-7d19a46bab28', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.4694003134385025', 'messages': '00000000000000000000000000000003.0.42328498149452565', 'branch:to:chat': '00000000000000000000000000000003.0.42328498149452565'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.9703901308038636'}, 'chat': {'branch:to:chat': '00000000000000000000000000000002.0.4694003134385025'}}, 'updated_channels': ['messages'], 'channel_values': {'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]}}\n",
      "{'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]}\n",
      "Checkpoint state before {'v': 4, 'ts': '2026-01-16T05:25:45.488119+00:00', 'id': '1f0f29bc-efac-6e46-8001-7d19a46bab28', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.4694003134385025', 'messages': '00000000000000000000000000000003.0.42328498149452565', 'branch:to:chat': '00000000000000000000000000000003.0.42328498149452565'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.9703901308038636'}, 'chat': {'branch:to:chat': '00000000000000000000000000000002.0.4694003134385025'}}, 'updated_channels': ['messages'], 'channel_values': {'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]}}\n",
      "Checkpoint state after {'v': 4, 'ts': '2026-01-16T05:26:02.403476+00:00', 'id': '1f0f29bd-90fe-62a4-8004-3b82e34b991d', 'channel_versions': {'__start__': '00000000000000000000000000000005.0.011645066966524564', 'messages': '00000000000000000000000000000006.0.9363323152658554', 'branch:to:chat': '00000000000000000000000000000006.0.9363323152658554'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000004.0.9217658067283898'}, 'chat': {'branch:to:chat': '00000000000000000000000000000005.0.011645066966524564'}}, 'updated_channels': ['messages'], 'channel_values': {'messages': [HumanMessage(content='where is pune', additional_kwargs={}, response_metadata={}), AIMessage(content='Pune is a city located in the western Indian state of Maharashtra. It is situated approximately 150 kilometers (about 93 miles) southeast of Mumbai, the state capital. Pune is known for its educational institutions, cultural heritage, and as a major hub for the IT and automotive industries.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]}}\n",
      "{'messages': [HumanMessage(content='where is pune', additional_kwargs={}, response_metadata={}), AIMessage(content='Pune is a city located in the western Indian state of Maharashtra. It is situated approximately 150 kilometers (about 93 miles) southeast of Mumbai, the state capital. Pune is known for its educational institutions, cultural heritage, and as a major hub for the IT and automotive industries.', additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])]}\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# INSTALL (run once if needed)\n",
    "# =========================================================\n",
    "# !pip install -U langgraph langchain langchain-openai langchain-community chromadb gradio tiktoken\n",
    "\n",
    "# =========================================================\n",
    "# IMPORTS\n",
    "# =========================================================\n",
    "from typing import List, TypedDict\n",
    "import tiktoken\n",
    "import gradio as gr\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# =========================================================\n",
    "# STATE\n",
    "# =========================================================\n",
    "class ChatState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    summary: str\n",
    "\n",
    "# =========================================================\n",
    "# LLM + TOKEN UTILS\n",
    "# =========================================================\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "def token_count(messages: List[BaseMessage]) -> int:\n",
    "    return len(encoder.encode(\" \".join(m.content for m in messages)))\n",
    "\n",
    "MAX_TOKENS = 2000\n",
    "KEEP_LAST_N = 6\n",
    "\n",
    "# =========================================================\n",
    "# VECTOR MEMORY (FACTS)\n",
    "# =========================================================\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"user_facts\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "FACT_PROMPT = \"\"\"\n",
    "Extract explicit user facts (name, job, preferences).\n",
    "Return one fact per line.\n",
    "If none, return empty.\n",
    "\"\"\"\n",
    "\n",
    "def extract_and_store_facts(text: str):\n",
    "    facts = llm.invoke(FACT_PROMPT + \"\\n\\n\" + text).content.strip()\n",
    "    if not facts:\n",
    "        return\n",
    "    for fact in facts.split(\"\\n\"):\n",
    "        vectorstore.add_texts([fact])\n",
    "\n",
    "def retrieve_facts(query: str) -> str:\n",
    "    docs = vectorstore.similarity_search(query, k=3)\n",
    "    return \"\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "# =========================================================\n",
    "# SUMMARIZATION NODE\n",
    "# =========================================================\n",
    "SUMMARY_PROMPT = \"\"\"\n",
    "You are compressing conversation history.\n",
    "\n",
    "Existing summary:\n",
    "{summary}\n",
    "\n",
    "New messages:\n",
    "{content}\n",
    "\n",
    "Preserve:\n",
    "- user facts\n",
    "- decisions\n",
    "- goals\n",
    "\"\"\"\n",
    "\n",
    "def summarize_node(state: ChatState):\n",
    "    messages = state[\"messages\"]\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    if token_count(messages) <= MAX_TOKENS:\n",
    "        return state\n",
    "\n",
    "    to_summarize = messages[:-KEEP_LAST_N]\n",
    "    recent = messages[-KEEP_LAST_N:]\n",
    "\n",
    "    content = \"\\n\".join(m.content for m in to_summarize)\n",
    "\n",
    "    new_summary = llm.invoke(\n",
    "        SUMMARY_PROMPT.format(summary=summary, content=content)\n",
    "    ).content\n",
    "\n",
    "    return {\n",
    "        \"summary\": new_summary,\n",
    "        \"messages\": recent\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# CHAT NODE\n",
    "# =========================================================\n",
    "def chat_node(state: ChatState):\n",
    "    last_user_text = state[\"messages\"][-1].content\n",
    "\n",
    "    extract_and_store_facts(last_user_text)\n",
    "    facts = retrieve_facts(last_user_text)\n",
    "\n",
    "    system = SystemMessage(\n",
    "        content=f\"\"\"\n",
    "Conversation summary:\n",
    "{state.get(\"summary\", \"\")}\n",
    "\n",
    "Long-term user facts:\n",
    "{facts}\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    response = llm.invoke([system] + state[\"messages\"])\n",
    "\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [\n",
    "            AIMessage(content=response.content)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# GRAPH\n",
    "# =========================================================\n",
    "def should_summarize(state: ChatState):\n",
    "    return \"summarize\" if token_count(state[\"messages\"]) > MAX_TOKENS else END\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat\", chat_node)\n",
    "graph.add_node(\"summarize\", summarize_node)\n",
    "\n",
    "graph.set_entry_point(\"chat\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"chat\",\n",
    "    should_summarize,\n",
    "    {\n",
    "        \"summarize\": \"summarize\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"summarize\", END)\n",
    "\n",
    "# =========================================================\n",
    "# CHECKPOINTING (IN-MEMORY)\n",
    "# =========================================================\n",
    "checkpointer = MemorySaver()\n",
    "app = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "# =========================================================\n",
    "# GRADIO UI\n",
    "# =========================================================\n",
    "config = {\"configurable\": {\"thread_id\": \"user-1\"}}\n",
    "\n",
    "def chat(user_input, history):\n",
    "    print(\"Checkpoint state before\", checkpointer.get(config))\n",
    "    result = app.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_input)]},\n",
    "        config=config\n",
    "    )\n",
    "    print(\"Checkpoint state after\", checkpointer.get(config))\n",
    "    print(result)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "print(\"Checking state\", checkpointer)\n",
    "gr.ChatInterface(\n",
    "    chat,\n",
    "    title=\"LangGraph Chatbot (Summary + Vector Memory + Checkpointing)\"\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
