{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Sending reply:\n",
      " Thanks for reaching out. We've refunded the duplicate charge.\n",
      "üì§ Sending reply:\n",
      " Thanks for reaching out. We've refunded the duplicate charge.\n",
      "‚úÖ Workflow complete\n",
      "üìä Feedback: [{'message': 'I was charged twice for my subscription last month.', 'draft': 'Escalating this issue to a human support agent.', 'rating': 5, 'comment': 'Draft was accurate and saved time.'}]\n"
     ]
    }
   ],
   "source": [
    "# PS: Deliverable: An agent with at least two HITL checkpoints and a feedback collection mechanism.\n",
    "\n",
    "# ===============================\n",
    "# INSTALL\n",
    "# ===============================\n",
    "# !pip install -U langgraph langchain langchain-openai\n",
    "\n",
    "import json\n",
    "from typing import TypedDict, Optional, List, Dict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.types import interrupt\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ===============================\n",
    "# FEEDBACK STORE\n",
    "# ===============================\n",
    "DRAFT_FEEDBACK: List[Dict] = []\n",
    "\n",
    "# ===============================\n",
    "# STATE\n",
    "# ===============================\n",
    "class SupportState(TypedDict):\n",
    "    customerMessage: str\n",
    "\n",
    "    autoReplyAllowed: bool\n",
    "    confidence: float\n",
    "\n",
    "    draftReply: Optional[str]\n",
    "    approvedReply: Optional[str]\n",
    "\n",
    "    approved: bool\n",
    "\n",
    "    feedbackRating: Optional[int]\n",
    "    feedbackComment: Optional[str]\n",
    "\n",
    "# ===============================\n",
    "# LLM\n",
    "# ===============================\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# ===============================\n",
    "# NODES\n",
    "# ===============================\n",
    "\n",
    "def assess_auto_reply(state: SupportState) -> SupportState:\n",
    "    prompt = f\"\"\"\n",
    "    You are a support operations assistant.\n",
    "\n",
    "    Decide if this message can be safely auto-replied.\n",
    "    Return STRICT JSON:\n",
    "\n",
    "    {{\n",
    "    \"autoReplyAllowed\": true|false,\n",
    "    \"confidence\": number between 0 and 1\n",
    "    }}\n",
    "\n",
    "    Message:\n",
    "    \"{state['customerMessage']}\"\n",
    "    \"\"\"\n",
    "    resp = llm.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    data = json.loads(resp.content)\n",
    "\n",
    "    state[\"autoReplyAllowed\"] = data[\"autoReplyAllowed\"]\n",
    "    state[\"confidence\"] = float(data[\"confidence\"])\n",
    "    return state\n",
    "\n",
    "\n",
    "# üî¥ HITL #1 ‚Äî LOW CONFIDENCE AUTO-REPLY\n",
    "def auto_reply_confidence_gate(state: SupportState) -> SupportState:\n",
    "    if state[\"confidence\"] < 0.75:\n",
    "        interrupt({\n",
    "            \"type\": \"auto_reply_uncertain\",\n",
    "            \"message\": \"Low confidence auto-reply decision\",\n",
    "            \"confidence\": state[\"confidence\"],\n",
    "            \"messagePreview\": state[\"customerMessage\"]\n",
    "        })\n",
    "    return state\n",
    "\n",
    "\n",
    "def draft_reply(state: SupportState) -> SupportState:\n",
    "    if not state[\"autoReplyAllowed\"]:\n",
    "        state[\"draftReply\"] = \"Escalating this issue to a human support agent.\"\n",
    "        return state\n",
    "\n",
    "    resp = llm.invoke([\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Draft a professional support reply:\n",
    "\n",
    "Customer message:\n",
    "\"{state['customerMessage']}\"\n",
    "\"\"\")\n",
    "    ])\n",
    "    state[\"draftReply\"] = resp.content\n",
    "    return state\n",
    "\n",
    "\n",
    "# üî¥ HITL #2 ‚Äî HUMAN APPROVES OR EDITS DRAFT\n",
    "def approval_gate(state: SupportState) -> SupportState:\n",
    "    if not state[\"approved\"]:\n",
    "        interrupt({\n",
    "            \"type\": \"approve_reply\",\n",
    "            \"draft\": state[\"draftReply\"]\n",
    "        })\n",
    "    return state\n",
    "\n",
    "\n",
    "def send_reply(state: SupportState) -> SupportState:\n",
    "    state[\"approvedReply\"] = state[\"approvedReply\"] or state[\"draftReply\"]\n",
    "    print(\"üì§ Sending reply:\\n\", state[\"approvedReply\"])\n",
    "    return state\n",
    "\n",
    "\n",
    "# üü° FEEDBACK\n",
    "def feedback_gate(state: SupportState) -> SupportState:\n",
    "    if state[\"feedbackRating\"] is None:\n",
    "        interrupt({\n",
    "            \"type\": \"draft_feedback\",\n",
    "            \"draft\": state[\"draftReply\"]\n",
    "        })\n",
    "    return state\n",
    "\n",
    "\n",
    "def store_feedback(state: SupportState) -> SupportState:\n",
    "    DRAFT_FEEDBACK.append({\n",
    "        \"message\": state[\"customerMessage\"],\n",
    "        \"draft\": state[\"draftReply\"],\n",
    "        \"rating\": state[\"feedbackRating\"],\n",
    "        \"comment\": state[\"feedbackComment\"]\n",
    "    })\n",
    "    return state\n",
    "\n",
    "# ===============================\n",
    "# GRAPH\n",
    "# ===============================\n",
    "builder = StateGraph(SupportState)\n",
    "\n",
    "builder.add_node(\"assess\", assess_auto_reply)\n",
    "builder.add_node(\"confidence_gate\", auto_reply_confidence_gate)\n",
    "builder.add_node(\"draft\", draft_reply)\n",
    "builder.add_node(\"approval_gate\", approval_gate)\n",
    "builder.add_node(\"send\", send_reply)\n",
    "builder.add_node(\"feedback_gate\", feedback_gate)\n",
    "builder.add_node(\"store_feedback\", store_feedback)\n",
    "\n",
    "builder.set_entry_point(\"assess\")\n",
    "\n",
    "builder.add_edge(\"assess\", \"confidence_gate\")\n",
    "builder.add_edge(\"confidence_gate\", \"draft\")\n",
    "builder.add_edge(\"draft\", \"approval_gate\")\n",
    "builder.add_edge(\"approval_gate\", \"send\")\n",
    "builder.add_edge(\"send\", \"feedback_gate\")\n",
    "builder.add_edge(\"feedback_gate\", \"store_feedback\")\n",
    "builder.add_edge(\"store_feedback\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# ===============================\n",
    "# RUN\n",
    "# ===============================\n",
    "state = {\n",
    "    \"customerMessage\": \"I was charged twice for my subscription last month.\",\n",
    "    \"autoReplyAllowed\": False,\n",
    "    \"confidence\": 0.0,\n",
    "    \"draftReply\": None,\n",
    "    \"approvedReply\": None,\n",
    "    \"approved\": False,\n",
    "    \"feedbackRating\": None,\n",
    "    \"feedbackComment\": None\n",
    "}\n",
    "\n",
    "# 1Ô∏è‚É£ Run ‚Üí may pause at confidence\n",
    "state = graph.invoke(state)\n",
    "\n",
    "# Human decides auto-reply is OK\n",
    "state[\"autoReplyAllowed\"] = True\n",
    "\n",
    "# 2Ô∏è‚É£ Resume ‚Üí pause at approval\n",
    "state = graph.invoke(state)\n",
    "\n",
    "# Human edits & approves\n",
    "state[\"approved\"] = True\n",
    "state[\"approvedReply\"] = \"Thanks for reaching out. We've refunded the duplicate charge.\"\n",
    "\n",
    "# 3Ô∏è‚É£ Resume ‚Üí pause at feedback\n",
    "state = graph.invoke(state)\n",
    "\n",
    "# Feedback\n",
    "state[\"feedbackRating\"] = 5\n",
    "state[\"feedbackComment\"] = \"Draft was accurate and saved time.\"\n",
    "\n",
    "final_state = graph.invoke(state)\n",
    "\n",
    "print(\"‚úÖ Workflow complete\")\n",
    "print(\"üìä Feedback:\", DRAFT_FEEDBACK)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
